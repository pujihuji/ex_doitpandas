{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concat 메서드 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "    A   B   C   D\n",
      "0  a4  b4  c4  d4\n",
      "1  a5  b5  c5  d5\n",
      "2  a6  b6  c6  d6\n",
      "3  a7  b7  c7  d7\n",
      "     A    B    C    D\n",
      "0   a8   b8   c8   d8\n",
      "1   a9   b9   c9   d9\n",
      "2  a10  b10  c10  d10\n",
      "3  a11  b11  c11  d11\n",
      "     A    B    C    D\n",
      "0   a0   b0   c0   d0\n",
      "1   a1   b1   c1   d1\n",
      "2   a2   b2   c2   d2\n",
      "3   a3   b3   c3   d3\n",
      "0   a4   b4   c4   d4\n",
      "1   a5   b5   c5   d5\n",
      "2   a6   b6   c6   d6\n",
      "3   a7   b7   c7   d7\n",
      "0   a8   b8   c8   d8\n",
      "1   a9   b9   c9   d9\n",
      "2  a10  b10  c10  d10\n",
      "3  a11  b11  c11  d11\n",
      "     A    B    C    D\n",
      "3   a3   b3   c3   d3\n",
      "3   a7   b7   c7   d7\n",
      "3  a11  b11  c11  d11\n",
      "_______________\n",
      "A    a3\n",
      "B    b3\n",
      "C    c3\n",
      "D    d3\n",
      "Name: 3, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1=pd.read_csv('../data/concat_1.csv')\n",
    "df2=pd.read_csv('../data/concat_2.csv')\n",
    "df3=pd.read_csv('../data/concat_3.csv')\n",
    "\n",
    "print(df1)\n",
    "print(df2)\n",
    "print(df3)\n",
    "\n",
    "row_concat=pd.concat([df1,df2,df3])\n",
    "print(row_concat)\n",
    "\n",
    "#loc은 인덱스 값이 3을갖는 자료들 전부추출\n",
    "print(row_concat.loc[3])\n",
    "print('_______________')\n",
    "#iloc은 위치가 3(4번째) 자료추출\n",
    "print(row_concat.iloc[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터프레임에 시리즈 연결하기\n",
    "## 시리즈에는 열이름이 없기에 새로운 열 요소 추가로 간주!!! -> 데이터프레임형식으로 칼럼별 값지정하여 추가해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D    0\n",
      "0   a0   b0   c0   d0  NaN\n",
      "1   a1   b1   c1   d1  NaN\n",
      "2   a2   b2   c2   d2  NaN\n",
      "3   a3   b3   c3   d3  NaN\n",
      "0  NaN  NaN  NaN  NaN   n1\n",
      "1  NaN  NaN  NaN  NaN   n2\n",
      "2  NaN  NaN  NaN  NaN   n3\n",
      "3  NaN  NaN  NaN  NaN   n4\n",
      "    A   B   C   D\n",
      "0  n1  n2  n3  n4\n",
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "0  n1  n2  n3  n4\n"
     ]
    }
   ],
   "source": [
    "new_series=pd.Series(['n1','n2','n3','n4'])\n",
    "print(pd.concat([df1,new_series]))\n",
    "\n",
    "new_row=pd.DataFrame([['n1','n2','n3','n4']],columns=['A','B','C','D'])\n",
    "print(new_row)\n",
    "print(pd.concat([df1,new_row]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 행 '1개'로 구성된 데이터프레임 생성하여 연결하기 --현재 사라짐!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#다른 방법들\n",
    "#1개인경우만 가능한  append --> pandas2.0부터 불가능!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다양한 방법으로 데이터 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A    B    C    D\n",
      "0    a0   b0   c0   d0\n",
      "1    a1   b1   c1   d1\n",
      "2    a2   b2   c2   d2\n",
      "3    a3   b3   c3   d3\n",
      "4    a4   b4   c4   d4\n",
      "5    a5   b5   c5   d5\n",
      "6    a6   b6   c6   d6\n",
      "7    a7   b7   c7   d7\n",
      "8    a8   b8   c8   d8\n",
      "9    a9   b9   c9   d9\n",
      "10  a10  b10  c10  d10\n",
      "11  a11  b11  c11  d11\n",
      "    A   B   C   D   A   B   C   D    A    B    C    D\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8\n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9\n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10\n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11\n",
      "    A   A    A\n",
      "0  a0  a4   a8\n",
      "1  a1  a5   a9\n",
      "2  a2  a6  a10\n",
      "3  a3  a7  a11\n",
      "    A   B   C   D   A   B   C   D    A    B    C    D new_col\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8      n1\n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9      n2\n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10      n3\n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11      n4\n",
      "   0   1   2   3   4   5   6   7    8    9    10   11\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8\n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9\n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10\n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "#모든자료를 합친후 인덱스 새로 순서대로 부여\n",
    "row_concat_i=pd.concat([df1,df2,df3],ignore_index=True)\n",
    "print(row_concat_i)\n",
    "\n",
    "#열방향으로 병합 axis=1 ,(행으로 추가는 axis=0)\n",
    "col_concat=pd.concat([df1,df2,df3],axis=1)\n",
    "print(col_concat)\n",
    "print(col_concat['A'])\n",
    "\n",
    "#새로운열 추가 데이터프레임명[추가할칼럼명]=[각 행에서 해당 열에 입력될 값들]\n",
    "col_concat['new_col']=['n1','n2','n3','n4']\n",
    "print(col_concat)\n",
    "\n",
    "#열방향병합+인덱스새로부여\n",
    "print(pd.concat([df1,df2,df3],axis=1,ignore_index=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 공통 열과 공통 인덱스만 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    E   F   G   H\n",
      "4  a4  b4  c4  d4\n",
      "5  a5  b5  c5  d5\n",
      "6  a6  b6  c6  d6\n",
      "7  a7  b7  c7  d7\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     A    B    C    D    E    F    G    H\n",
      "0   a0   b0   c0   d0  NaN  NaN  NaN  NaN\n",
      "1   a1   b1   c1   d1  NaN  NaN  NaN  NaN\n",
      "2   a2   b2   c2   d2  NaN  NaN  NaN  NaN\n",
      "3   a3   b3   c3   d3  NaN  NaN  NaN  NaN\n",
      "4  NaN  NaN  NaN  NaN   a4   b4   c4   d4\n",
      "5  NaN  NaN  NaN  NaN   a5   b5   c5   d5\n",
      "6  NaN  NaN  NaN  NaN   a6   b6   c6   d6\n",
      "7  NaN  NaN  NaN  NaN   a7   b7   c7   d7\n",
      "0   a8  NaN   b8  NaN  NaN   c8  NaN   d8\n",
      "2   a9  NaN   b9  NaN  NaN   c9  NaN   d9\n",
      "5  a10  NaN  b10  NaN  NaN  c10  NaN  d10\n",
      "7  a11  NaN  b11  NaN  NaN  c11  NaN  d11\n",
      "_____열 방향 병합(수직병합)_________\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 4, 5, 6, 7, 0, 2, 5, 7]\n",
      "_\n",
      "     A    B    C    D    E    F    G    H\n",
      "0   a0   b0   c0   d0  NaN  NaN  NaN  NaN\n",
      "1   a1   b1   c1   d1  NaN  NaN  NaN  NaN\n",
      "2   a2   b2   c2   d2  NaN  NaN  NaN  NaN\n",
      "3   a3   b3   c3   d3  NaN  NaN  NaN  NaN\n",
      "4  NaN  NaN  NaN  NaN   a4   b4   c4   d4\n",
      "5  NaN  NaN  NaN  NaN   a5   b5   c5   d5\n",
      "6  NaN  NaN  NaN  NaN   a6   b6   c6   d6\n",
      "7  NaN  NaN  NaN  NaN   a7   b7   c7   d7\n",
      "0   a8  NaN   b8  NaN  NaN   c8  NaN   d8\n",
      "2   a9  NaN   b9  NaN  NaN   c9  NaN   d9\n",
      "5  a10  NaN  b10  NaN  NaN  c10  NaN  d10\n",
      "7  a11  NaN  b11  NaN  NaN  c11  NaN  d11\n",
      "     A    C\n",
      "0   a0   c0\n",
      "1   a1   c1\n",
      "2   a2   c2\n",
      "3   a3   c3\n",
      "4   a8   b8\n",
      "5   a9   b9\n",
      "6  a10  b10\n",
      "7  a11  b11\n",
      "_____행 방향 병합(수평병합)_________\n",
      "    E   F   G   H\n",
      "4  a4  b4  c4  d4\n",
      "5  a5  b5  c5  d5\n",
      "6  a6  b6  c6  d6\n",
      "7  a7  b7  c7  d7\n",
      "Empty DataFrame\n",
      "Columns: [A, B, C, D, E, F, G, H, A, C, F, H]\n",
      "Index: []\n",
      "    A   B   C   D   A   C   F   H\n",
      "0  a0  b0  c0  d0  a8  b8  c8  d8\n",
      "2  a2  b2  c2  d2  a9  b9  c9  d9\n"
     ]
    }
   ],
   "source": [
    "#각 데이터프레임 칼럼명 재지정\n",
    "df1.columns=['A','B','C','D']\n",
    "df2.columns=['E','F','G','H']\n",
    "df3.columns=['A','C','F','H']\n",
    "print(df2)\n",
    "print(type(df2))\n",
    "\n",
    "rowconcat=pd.concat([df1,df2,df3])\n",
    "print(rowconcat)\n",
    "\n",
    "print('_____열 방향 병합(수직병합)_________')\n",
    "#공통항목만 출력 \n",
    "#3개전부 공통항목 = 없음\n",
    "print(pd.concat([df1,df2,df3],join='inner'))\n",
    "print('_')\n",
    "print(pd.concat([df1,df2,df3],join='outer'))\n",
    "#df1,df3공통 항목(동일하게 존재하는 열)\n",
    "print(pd.concat([df1,df3],join='inner',ignore_index=True))\n",
    "\n",
    "print('_____행 방향 병합(수평병합)_________')\n",
    "df1.index=[0,1,2,3]\n",
    "df2.index=[4,5,6,7]\n",
    "df3.index=[0,2,5,7]\n",
    "\n",
    "\n",
    "print(df2)\n",
    "colconcat=pd.concat([df1,df2,df3],axis=1,join='inner')\n",
    "print(colconcat)\n",
    "#df1,df3공통 항목(동일하게 존재하는 인덱스)\n",
    "print(pd.concat([df1,df3],join='inner',axis=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge 메서드 사용하기  - concat은 인덱스나 칼럼명을 기준으로 // merge는 내부조인기본\n",
    "## 일치해야할 left_on의 열 요소와 right_on의 열요소 설정 (여러개 설정도 가능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ident   personal    family\n",
      "0      dyer    William      Dyer\n",
      "1        pb      Frank   Pabodie\n",
      "2      lake   Anderson      Lake\n",
      "3       roe  Valentina   Roerich\n",
      "4  danforth      Frank  Danforth\n",
      "    name    lat    long\n",
      "0   DR-1 -49.85 -128.57\n",
      "1   DR-3 -47.15 -126.72\n",
      "2  MSK-4 -48.87 -123.40\n",
      "    taken person quant  reading\n",
      "0     619   dyer   rad     9.82\n",
      "1     619   dyer   sal     0.13\n",
      "2     622   dyer   rad     7.80\n",
      "3     622   dyer   sal     0.09\n",
      "4     734     pb   rad     8.41\n",
      "5     734   lake   sal     0.05\n",
      "6     734     pb  temp   -21.50\n",
      "7     735     pb   rad     7.22\n",
      "8     735    NaN   sal     0.06\n",
      "9     735    NaN  temp   -26.00\n",
      "10    751     pb   rad     4.35\n",
      "11    751     pb  temp   -18.50\n",
      "12    751   lake   sal     0.10\n",
      "13    752   lake   rad     2.19\n",
      "14    752   lake   sal     0.09\n",
      "15    752   lake  temp   -16.00\n",
      "16    752    roe   sal    41.60\n",
      "17    837   lake   rad     1.46\n",
      "18    837   lake   sal     0.21\n",
      "19    837    roe   sal    22.50\n",
      "20    844    roe   rad    11.25\n",
      "   ident   site       dated\n",
      "0    619   DR-1  1927-02-08\n",
      "1    622   DR-1  1927-02-10\n",
      "2    734   DR-3  1939-01-07\n",
      "3    735   DR-3  1930-01-12\n",
      "4    751   DR-3  1930-02-26\n",
      "5    752   DR-3         NaN\n",
      "6    837  MSK-4  1932-01-14\n",
      "7    844   DR-1  1932-03-22\n",
      "___________\n",
      "   ident   site       dated\n",
      "0    619   DR-1  1927-02-08\n",
      "2    734   DR-3  1939-01-07\n",
      "6    837  MSK-4  1932-01-14\n",
      "___________\n",
      "    name    lat    long  ident   site       dated\n",
      "0   DR-1 -49.85 -128.57    619   DR-1  1927-02-08\n",
      "1   DR-3 -47.15 -126.72    734   DR-3  1939-01-07\n",
      "2  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14\n",
      "___________\n",
      "    name    lat    long  ident   site       dated\n",
      "0   DR-1 -49.85 -128.57    619   DR-1  1927-02-08\n",
      "1   DR-1 -49.85 -128.57    622   DR-1  1927-02-10\n",
      "2   DR-1 -49.85 -128.57    844   DR-1  1932-03-22\n",
      "3   DR-3 -47.15 -126.72    734   DR-3  1939-01-07\n",
      "4   DR-3 -47.15 -126.72    735   DR-3  1930-01-12\n",
      "5   DR-3 -47.15 -126.72    751   DR-3  1930-02-26\n",
      "6   DR-3 -47.15 -126.72    752   DR-3         NaN\n",
      "7  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14\n",
      "______***_____\n",
      "   ident_x   personal   family  taken_x person_x quant  reading_x  ident_y  \\\n",
      "0     dyer    William     Dyer      619     dyer   rad       9.82      619   \n",
      "1     dyer    William     Dyer      619     dyer   sal       0.13      619   \n",
      "2     dyer    William     Dyer      622     dyer   rad       7.80      622   \n",
      "3     dyer    William     Dyer      622     dyer   sal       0.09      622   \n",
      "4       pb      Frank  Pabodie      734       pb   rad       8.41      734   \n",
      "5       pb      Frank  Pabodie      734       pb  temp     -21.50      734   \n",
      "6       pb      Frank  Pabodie      735       pb   rad       7.22      735   \n",
      "7       pb      Frank  Pabodie      751       pb   rad       4.35      751   \n",
      "8       pb      Frank  Pabodie      751       pb  temp     -18.50      751   \n",
      "9     lake   Anderson     Lake      734     lake   sal       0.05      734   \n",
      "10    lake   Anderson     Lake      751     lake   sal       0.10      751   \n",
      "11    lake   Anderson     Lake      752     lake   rad       2.19      752   \n",
      "12    lake   Anderson     Lake      752     lake   sal       0.09      752   \n",
      "13    lake   Anderson     Lake      752     lake  temp     -16.00      752   \n",
      "14    lake   Anderson     Lake      837     lake   rad       1.46      837   \n",
      "15    lake   Anderson     Lake      837     lake   sal       0.21      837   \n",
      "16     roe  Valentina  Roerich      752      roe   sal      41.60      752   \n",
      "17     roe  Valentina  Roerich      837      roe   sal      22.50      837   \n",
      "18     roe  Valentina  Roerich      844      roe   rad      11.25      844   \n",
      "\n",
      "     site       dated  taken_y person_y  reading_y  \n",
      "0    DR-1  1927-02-08      619     dyer       9.82  \n",
      "1    DR-1  1927-02-08      619     dyer       0.13  \n",
      "2    DR-1  1927-02-10      622     dyer       7.80  \n",
      "3    DR-1  1927-02-10      622     dyer       0.09  \n",
      "4    DR-3  1939-01-07      734       pb       8.41  \n",
      "5    DR-3  1939-01-07      734       pb     -21.50  \n",
      "6    DR-3  1930-01-12      735       pb       7.22  \n",
      "7    DR-3  1930-02-26      751       pb       4.35  \n",
      "8    DR-3  1930-02-26      751       pb     -18.50  \n",
      "9    DR-3  1939-01-07      734     lake       0.05  \n",
      "10   DR-3  1930-02-26      751     lake       0.10  \n",
      "11   DR-3         NaN      752     lake       2.19  \n",
      "12   DR-3         NaN      752     lake       0.09  \n",
      "13   DR-3         NaN      752     lake     -16.00  \n",
      "14  MSK-4  1932-01-14      837     lake       1.46  \n",
      "15  MSK-4  1932-01-14      837     lake       0.21  \n",
      "16   DR-3         NaN      752      roe      41.60  \n",
      "17  MSK-4  1932-01-14      837      roe      22.50  \n",
      "18   DR-1  1932-03-22      844      roe      11.25  \n",
      "___________\n",
      "ident_x          lake\n",
      "personal     Anderson\n",
      "family           Lake\n",
      "taken_x           752\n",
      "person_x         lake\n",
      "quant            temp\n",
      "reading_x       -16.0\n",
      "ident_y           752\n",
      "site             DR-3\n",
      "dated             NaN\n",
      "taken_y           752\n",
      "person_y         lake\n",
      "reading_y       -16.0\n",
      "Name: 13, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "person=pd.read_csv('../data/survey_person.csv')\n",
    "site=pd.read_csv('../data/survey_site.csv')\n",
    "survey=pd.read_csv('../data/survey_survey.csv')\n",
    "visited=pd.read_csv('../data/survey_visited.csv')\n",
    "\n",
    "print(person)\n",
    "print(site)\n",
    "print(survey)\n",
    "print(visited)\n",
    "print('___________')\n",
    "visited_subset=visited.iloc[[0,2,6]]\n",
    "print(visited_subset)\n",
    "print('___________')\n",
    "#일치해야할 left_on의 열 요소와 right_on의 열요소 설정 left.merge(right, left_on='leftcolumn', right_on='rightcolumn')\n",
    "o2o_merge=site.merge(visited_subset,left_on='name',right_on='site')\n",
    "print(o2o_merge)\n",
    "print('___________')\n",
    "b2o_merge=site.merge(visited,left_on='name',right_on='site')\n",
    "print(b2o_merge)\n",
    "print('______***_____')\n",
    "#여러개의 left_on right_on 설정시\n",
    "ps=person.merge(survey,left_on='ident',right_on='person')\n",
    "vs=visited.merge(survey,left_on='ident',right_on='taken')\n",
    "ps_vs=ps.merge(vs,left_on=['ident','taken','quant'],right_on=['person','ident','quant'])\n",
    "print(ps_vs)\n",
    "print('___________')\n",
    "print(ps_vs.iloc[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
